{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "conf = SparkConf().setAppName(\"MLlib\")\n",
    "sc = SparkContext(conf=conf)\n",
    "# sc = pyspark.SparkContext(\"local\")\n",
    "sc.setLogLevel(\"WARN\")\n",
    "# sc.stop() if need to \n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(r\"C:\\Users\\yaqi dai\\Desktop\\UCONN\\130-THIRD SEMESTER\\5671 Financial Data Mining and Big Data Analytics\\project_71\\Train_small.csv\", inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = data.columns\n",
    "colname.remove('_c0')\n",
    "colname.remove('up_down')\n",
    "feature = VectorAssembler(inputCols = colname,outputCol=\"features\")\n",
    "data2 = feature.transform(data)\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)\n",
    "normdata = normalizer.transform(data2)\n",
    "output = normdata.selectExpr(\"up_down as label\", \"normFeatures as features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = output.randomSplit([0.7, 0.3], seed = 300)\n",
    "lr = LogisticRegression(featuresCol = \"features\", labelCol = \"label\", maxIter=100)\n",
    "lrModel = lr.fit(train)\n",
    "predictions = lrModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is : 0.7382108163206589\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "p = evaluator.evaluate(predictions)\n",
    "print('the accuracy is :',p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = spark.read.format(\"csv\").option(\"header\", \"true\").load(r\"C:\\Users\\yaqi dai\\Desktop\\UCONN\\130-THIRD SEMESTER\\5671 Financial Data Mining and Big Data Analytics\\project_71\\Test_small_features.csv\", inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = data.columns\n",
    "colname.remove('_c0')\n",
    "colname.remove('up_down')\n",
    "feature = VectorAssembler(inputCols = colname,outputCol=\"features1\")\n",
    "test_data2 = feature.transform(test_data)\n",
    "normalizer = Normalizer(inputCol=\"features1\", outputCol=\"features\", p=1.0)\n",
    "testnorm = normalizer.transform(test_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = lrModel.transform(testnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.toPandas().to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = spark.read.format(\"csv\").option(\"header\", \"true\").load(r\"C:\\Users\\yaqi dai\\Desktop\\UCONN\\130-THIRD SEMESTER\\5671 Financial Data Mining and Big Data Analytics\\project_71\\Train_small.csv\", inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_colname = rf_data.columns\n",
    "rf_colname.remove('_c0')\n",
    "rf_colname.remove('up_down')\n",
    "rf_feature = VectorAssembler(inputCols = rf_colname,outputCol=\"features1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data2 = feature.transform(rf_data)\n",
    "rf_normalizer = Normalizer(inputCol=\"features1\", outputCol=\"normFeatures\", p=1.0)\n",
    "rf_normdata = rf_normalizer.transform(rf_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rf_output = rf_normdata.selectExpr(\"up_down as label\", \"normFeatures as features\")\n",
    "train, test = rf_output.randomSplit([0.8, 0.2], seed = 666)\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "rfModel = rf.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.327148\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32958\n",
       "1    16694\n",
       "Name: up_down, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\yaqi dai\\Desktop\\UCONN\\130-THIRD SEMESTER\\5671 Financial Data Mining and Big Data Analytics\\project_71\\Train_small.csv')\n",
    "df.head()\n",
    "# y is the ground truth\n",
    "y = df['up_down']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49652, 212)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "train = df.drop(['Unnamed: 0','up_down'], axis=1)\n",
    "X = train.as_matrix()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-val accuracy: 0.656892\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=666)\n",
    "\n",
    "\n",
    "modeling_pipeline = make_pipeline(RandomForestClassifier(n_estimators=10))\n",
    "cv_scores = cross_val_score(modeling_pipeline, X, y, scoring='accuracy')\n",
    "print(\"Cross-val accuracy: %f\" %cv_scores.mean())\n",
    "\n",
    "#rf = \n",
    "#rf.fit(X_tr, y_tr)\n",
    "#y_pr = rf.predict(X_te)\n",
    "#print(accuracy_score(y_te, y_pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "nn_data = spark.read.format(\"csv\").option(\"header\", \"true\").load(r\"C:\\Users\\yaqi dai\\Desktop\\UCONN\\130-THIRD SEMESTER\\5671 Financial Data Mining and Big Data Analytics\\project_71\\Train_small.csv\", inferSchema = True)\n",
    "\n",
    "# Split the data into train and test\n",
    "nn_colname = nn_data.columns\n",
    "nn_colname.remove('_c0')\n",
    "nn_colname.remove('up_down')\n",
    "nn_feature = VectorAssembler(inputCols = nn_colname,outputCol=\"features1\")\n",
    "nn_data2 = feature.transform(rf_data)\n",
    "nn_normalizer = Normalizer(inputCol=\"features1\", outputCol=\"normFeatures\", p=1.0)\n",
    "nn_normdata = nn_normalizer.transform(nn_data2)\n",
    "nn_output = nn_normdata.selectExpr(\"up_down as label\", \"normFeatures as features\")\n",
    "train, test = nn_output.randomSplit([0.6, 0.4], 1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify layers for the neural network:\n",
    "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "layers = [212, 100, 50, 10, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model = trainer.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.662308930008045\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on the test set\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
